


def inference_srl(generations, sanity_check):
    """ Constrained inference for the SRL task
    Inputs
    ------------
    generations- List[List[{"sentence":str, "score":float}]]. List of responses generated by the 
                prompt model. Size: (|dataset|,|beam|,2). The dictionary contains a candidate response
                along with its score.
    sanity_check - bool. If True, the gold answers are moved to top of the beam.  This helps to test the 
                inference algorithm in the ideal case. 
    """
    



INFERENCE_DICT = {
            "srl" : inference_srl,
            "coref": inference_coref

        }


def run_inference():
    return INFERENCE_DICT[task](generations, sanity)
