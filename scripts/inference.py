from graph import construct_graph, Graph
from gurobipy import Model, GRB, quicksum, abs_

import numpy as np
import pandas as pd
from tqdm import tqdm



def inference_srl(data, generations, sanity_check):
    """ Constrained inference for the SRL task
    Inputs
    ------------
    data - pd.DataFrame. Processed dataset
    generations- List[List[{"sentence":str, "score":float}]]. List of responses generated by the 
                prompt model. Size: (|dataset|,|beam|,2). The dictionary contains a candidate response
                along with its score.
    sanity_check - bool. If True, the gold answers are moved to top of the beam.  This helps to test the 
                inference algorithm in the ideal case. 
    """
    predicate = None
    sentence = None
    sent_id = None
    pred_gens = []
    const_ans = []
    gold_ans = []
    gold_ans_spans = []
    invalid_gold = 0

    cnt_ix = -1
    # iterate over the dataset
    for ix, row in tqdm(data.iterrows()):
        cnt_ix += 1
        if predicate == None:
            predicate = row["predicate"]
            sentence = row["sentence"]
            sent_id = row["sent_id"]
        
        # If thecondition is satisfied, we have the data points for the structure
        if ((predicate != row["predicate"]) or (sent_id != row["sent_id"])):
            predicate = row["predicate"]
            sent_id = row["sent_id"]
            
            c_ans, g_inv = construct_graph(sentence, pred_gens, ix , gold_ans, sanity_check, ans_span=gold_ans_spans)
            const_ans += c_ans      # Answers selected via the inference algorithm
            invalid_gold += g_inv   # All answers that are invalid (non-extarctive)
                
            sentence = row["sentence"]
            pred_gens = []
            gold_ans = []
            gold_ans_spans = []
        
        # Store answers and the gold answers
        pred_gens.append(generations[cnt_ix])
        gold_ans.append(row["answer"])
        # Gold answer spans for sanity check
        if "ans_span" in row.keys():
            gold_ans_spans.append(row["ans_span"])
    
    # Inference for the last structure
    c_ans, g_inv = construct_graph(sentence, pred_gens,len(data), gold_ans, sanity_check, ans_span=gold_ans_spans)
    const_ans += c_ans
    invalid_gold += g_inv
    print(f"# Gold answers not perfect sub-sequences: {invalid_gold}")
        
    return const_ans




def solve_coref(relations, preds, thresh=0.5):
    thresh = 0.5
    max_ent = np.max(relations)+1
    score_mat = np.full((max_ent,max_ent),-np.inf)
    for ix in range(len(preds)):
        for p in preds[ix]:
            if p['sentence'] == "Yes":
                score_y = p['score']
        #if relations[ix][0] < relations[ix][1]:
        #    low = 0
        #    high = 1
        #else:
        #    low = 1
        #    high = 0

        score_mat[relations[ix][0],relations[ix][1]] = score_y-thresh
        #score_mat[relations[ix][1],relations[ix][0]] = score_y-0.5
 
    #print(score_mat)

    model = Model('Optim')

    y = [[0]*max_ent for i in range(max_ent)]
    for i in range(max_ent):
        for j in range(i+1,max_ent):
            y_str = f"y{i}{j}"
            y[i][j] = model.addVar(vtype=GRB.BINARY, name=y_str)
    
    for i in range(max_ent):
        for j in range(i+1,max_ent):
            for k in range(j+1,max_ent):
                model.addConstr(y[i][j] + y[j][k] - y[i][k] <= 1)
                model.addConstr(y[i][k] + y[i][j] - y[j][k] <= 1)
                model.addConstr(y[i][k] + y[j][k] - y[i][j] <= 1)


    sum_const = 0
    for i in range(max_ent):
        for j in range(i+1, max_ent):
            sum_const += y[i][j]
    expr = abs_(sum_const)
    #model.addConstr(abs_(quicksum(y[i][j] for i in range(max_ent) for j in range(i+1,max_ent))) >= 1e-8)
    model.addConstr(sum_const >= 1)
    obj = quicksum(y[i][j]*score_mat[i][j] for i in range(max_ent) for j in range(i+1,max_ent))
    model.setObjective(obj, GRB.MAXIMIZE)
    model.optimize()
    
    final_y = [[0]*max_ent for i in range(max_ent)]
    for i in range(max_ent):
        for j in range(i+1,max_ent):
            final_y[i][j] = y[i][j].X
    
    answers = []
    for rel in relations:
        #if rel[0] < rel[1]:
        #    low = 0
        #    high = 1
        #else:
        #    low = 1
        #    high = 0
        if final_y[rel[0]][rel[1]] == 1:
            answers.append("Yes")
        else:
            answers.append("No")

    #print(final_y)
    return answers





def inference_coref(data, generations, sanity_check):
    """ Constrained inference for the SRL task
    Inputs
    ------------
    data - pd.DataFrame. Processed dataset
    generations- List[List[{"sentence":str, "score":float}]]. List of responses generated by the 
                prompt model. Size: (|dataset|,|beam|,2). The dictionary contains a candidate response
                along with its score.
    sanity_check - bool. If True, the gold answers are moved to top of the beam.  This helps to test the 
                inference algorithm in the ideal case. 
    """
    structure_ix = None
    doc_id = None
    pred_gens = []
    const_ans = []
    gold_ans = []
    relation_ids = []

    for ix, row in tqdm(data.iterrows()):
        if structure_ix == None:
            structure_ix = ix
            doc_id = row['doc_id']
        #if ix ==3:
        #    print(row.keys())
        #    print(row)
        #    exit()
        # When the doc_id changes, we need to consider the data we have
        # for constrained inference
        if doc_id != row['doc_id']:
            #print(relation_ids)
            struct_ans = solve_coref(relation_ids, pred_gens)
            const_ans.extend(struct_ans)
            #print(gold_ans)
            #print(struct_ans)
            #print()
            #print()
            #exit() 
            pred_gens = []
            gold_ans = []
            relation_ids = []
            doc_id = row['doc_id']

        pred_gens.append(generations[ix])
        gold_ans.append(row["answer"])
        if row['in_order']:
            relation_ids.append([row['mention_id1'],row["mention_id2"]])
        else:
            relation_ids.append([row["mention_id2"],row["mention_id1"]])
    
    struct_ans = solve_coref(relation_ids, pred_gens)
    const_ans.extend(struct_ans)

        
    return const_ans


INFERENCE_DICT = {
            "srl" : inference_srl,
            "coref": inference_coref

        }


def run_inference(task, data, generations, sanity):
    return INFERENCE_DICT[task](data, generations, sanity)
